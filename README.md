# rsb-10k
RSB-10K is a standardized benchmark protocol for evaluating whether large language models maintain stable reasoning under social, emotional, and authority-based framing pressure.

This repository contains:
- The RSB-10K protocol (v1)
- Prompt structure and dataset specification
- Metric definitions and reporting format
- Example scoring scripts (WIP)

The benchmark is model- and lab-agnostic, designed for reproducibility and cross-model comparison.

## Citation

If you use or adapt RSB-10K, please cite:

Huang, Y. (2025). *RSB-10K: Reasoning Stability Benchmark Under Framing Pressure (v1.0).*  
https://github.com/huangyoon/rsb-10k

## Status

v1.0 released. Prompt expansion and scoring pipeline being finalized.
